{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import random\n","import numpy as np\n","import torch\n","import torchvision\n","import torchvision.transforms as T\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.models.detection import maskrcnn_resnet50_fpn_v2\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n","from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval\n","import cv2\n","import matplotlib.pyplot as plt\n","import torchvision.transforms.functional as F\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8kLm8rb2Cmd8","outputId":"dbcaea80-cb11-42a6-a183-222ad0c981fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#### Copying dataset from drive to colab"],"metadata":{"id":"Vg4xZtmtHP1H"}},{"cell_type":"code","source":["!rsync -av --progress /content/drive/MyDrive/TACO/data /content/\n","data_dir = '/content/data'"],"metadata":{"id":"TWOpQ63Cf7pR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir = '/content/drive/MyDrive/TACO/data'"],"metadata":{"id":"NNwHWs4ggHx-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def resize_mask(mask, H, W):\n","    return cv2.resize(mask, (W, H), interpolation=cv2.INTER_NEAREST)\n","\n","ann_file = os.path.join(data_dir, 'annotations_0_train.json')\n","coco = COCO(ann_file)\n","\n","annotations_list = []\n","for img_id in coco.getImgIds():\n","    img_info = coco.loadImgs(img_id)[0]\n","    ann_ids = coco.getAnnIds(imgIds=img_id)\n","    annotations_list.append({\n","        'image_id': img_id,\n","        'file_name': img_info['file_name'],\n","        'ann_ids': ann_ids,\n","        'height': img_info['height'],\n","        'width': img_info['width']\n","    })"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WFO5VbnvC8IZ","outputId":"80484be8-ffa5-4c39-8c0d-73ff4490ae22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=3.05s)\n","creating index...\n","index created!\n"]}]},{"cell_type":"code","source":["class TACOInstanceSegmentationDataset(Dataset):\n","    def __init__(self, image_dir, annotation_list, coco, transforms=None):\n","        self.image_dir = image_dir\n","        self.annotations = annotation_list\n","        self.transforms = transforms\n","        self.coco = coco\n","\n","    def __getitem__(self, idx):\n","        ann = self.annotations[idx]\n","        img_path = os.path.join(self.image_dir, ann['file_name'])\n","        img = Image.open(img_path).convert(\"RGB\")\n","\n","        anns = self.coco.loadAnns(ann['ann_ids'])\n","        boxes, labels, masks = [], [], []\n","        H, W = ann['height'], ann['width']\n","\n","        for a in anns:\n","            x, y, w, h = a['bbox']\n","            if w < 1 or h < 1:\n","                continue\n","            boxes.append([x, y, x + w, y + h])\n","            labels.append(a['category_id'])\n","            mask = resize_mask(self.coco.annToMask(a).astype(np.uint8), H, W)\n","            masks.append(mask)\n","\n","        if not boxes:\n","            img = ToTensorV2()(image=img)[\"image\"]\n","            target = {\n","                'boxes': torch.zeros((0, 4), dtype=torch.float32),\n","                'labels': torch.zeros((0,), dtype=torch.int64),\n","                'masks': torch.zeros((0, H, W), dtype=torch.uint8),\n","                'image_id': torch.tensor([ann['image_id']])\n","            }\n","            return img, target\n","\n","        masks = np.stack(masks, axis=0) if masks else np.zeros((0, H, W), dtype=np.uint8)\n","        target = {\n","            'boxes': torch.as_tensor(boxes, dtype=torch.float32),\n","            'labels': torch.as_tensor(labels, dtype=torch.int64),\n","            'masks': torch.as_tensor(masks, dtype=torch.uint8),\n","            'image_id': torch.tensor([ann['image_id']])\n","        }\n","        if self.transforms:\n","            img = self.transforms(img)\n","\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.annotations)"],"metadata":{"id":"qvuSlUkVC_PP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -U albumentations"],"metadata":{"id":"cYeIbGgxpnzi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import albumentations as A\n","\n","transform = A.Compose([\n","    A.RandomCrop(width=512, height=512),\n","    A.HorizontalFlip(p=0.5),\n","    A.RandomBrightnessContrast(p=0.5),\n","    A.Normalize(),\n","], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']),\n","   mask_params=A.MaskParams())\n","\n","# transform = T.ToTensor()\n","dataset = TACOInstanceSegmentationDataset(data_dir, annotations_list, coco, transforms=transform)\n","data_loader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n","\n","\n","def get_model_instance_segmentation(num_classes):\n","    model = maskrcnn_resnet50_fpn_v2(weights=\"DEFAULT\")\n","\n","    in_features_box = model.roi_heads.box_predictor.cls_score.in_features\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_features_box, num_classes)\n","\n","    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n","    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, num_classes)\n","\n","    return model\n","\n","from torch.cuda.amp import GradScaler, autocast\n","\n","def train(model, optimizer, scaler, data_loader, device):\n","    model.train()\n","    for images, targets in data_loader:\n","        images = [img.to(device) for img in images]\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        optimizer.zero_grad()\n","        with autocast():\n","            loss_dict = model(images, targets)\n","            losses = sum(loss for loss in loss_dict.values())\n","\n","        scaler.scale(losses).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","def evaluate(model, dataset, coco_gt, device, num_images=100):\n","    model.eval()\n","    results = []\n","    image_ids = []\n","\n","    for idx in range(min(num_images, len(dataset))):\n","        img, _ = dataset[idx]\n","        img = img.to(device)\n","        with torch.no_grad():\n","            prediction = model([img])[0]\n","\n","        image_id = int(dataset.annotations[idx]['image_id'])\n","        image_ids.append(image_id)\n","\n","        for box, score, label in zip(prediction['boxes'], prediction['scores'], prediction['labels']):\n","            x1, y1, x2, y2 = box.tolist()\n","            w, h = x2 - x1, y2 - y1\n","            results.append({\n","                'image_id': image_id,\n","                'category_id': int(label),\n","                'bbox': [x1, y1, w, h],\n","                'score': float(score)\n","            })\n","\n","    if not results:\n","        print(\"No predictions to evaluate.\")\n","        return\n","\n","    coco_dt = coco_gt.loadRes(results)\n","    coco_eval = COCOeval(coco_gt, coco_dt, iouType='segm')\n","    coco_eval.evaluate()\n","    coco_eval.accumulate()\n","    coco_eval.summarize()\n","\n","\n","def show_prediction(image_tensor, pred, category_id_to_name, score_threshold=0.4):\n","    image_np = F.to_pil_image(image_tensor.cpu()).convert(\"RGB\")\n","    image_with_masks = np.array(image_np).copy()\n","\n","    boxes = pred['boxes'].cpu().numpy()\n","    scores = pred['scores'].cpu().numpy()\n","    labels = pred['labels'].cpu().numpy()\n","    masks = pred['masks'].cpu().numpy()\n","\n","    fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n","\n","    axs[0].imshow(image_np)\n","    axs[0].set_title(\"Original Image\")\n","    axs[0].axis(\"off\")\n","    axs[1].imshow(image_np)\n","    axs[1].set_title(\"Predictions\")\n","    ax = axs[1]\n","\n","    for i, score in enumerate(scores):\n","        if score < score_threshold:\n","            continue\n","\n","        x1, y1, x2, y2 = boxes[i]\n","        label_id = labels[i]\n","        class_name = category_id_to_name.get(label_id, f\"class {label_id}\")\n","        ax.add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1,\n","                                   fill=False, edgecolor='red', linewidth=2))\n","        ax.text(x1, y1 - 5, f\"{class_name}: {score:.2f}\",\n","                fontsize=12, color='white',\n","                bbox=dict(facecolor='red', alpha=0.5, edgecolor='none'))\n","\n","        mask = masks[i, 0]\n","        masked = np.ma.masked_where(mask < 0.5, mask)\n","        ax.imshow(masked, alpha=0.4, cmap='jet')\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"zeCyBmQ1DIg2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vU_S8CBlkNZ-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"35eeb0dc-5d10-45da-d39d-70e148934afc"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-42-bc1f012b121d>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 (frozen backbone)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-c75872ba0007>:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 (frozen backbone)\n","Epoch 3 (frozen backbone)\n","Epoch 4 (frozen backbone)\n","Epoch 5 (frozen backbone)\n","Epoch 6 (frozen backbone)\n","Epoch 7 (frozen backbone)\n","Epoch 8 (frozen backbone)\n","Epoch 9 (frozen backbone)\n","Epoch 10 (frozen backbone)\n","Epoch 11 (fine-tuning)\n","Epoch 12 (fine-tuning)\n","Epoch 13 (fine-tuning)\n","Epoch 14 (fine-tuning)\n","Epoch 15 (fine-tuning)\n","Epoch 16 (fine-tuning)\n","Epoch 17 (fine-tuning)\n","Epoch 18 (fine-tuning)\n","Epoch 19 (fine-tuning)\n","Epoch 20 (fine-tuning)\n","Epoch 21 (fine-tuning)\n","Epoch 22 (fine-tuning)\n","Epoch 23 (fine-tuning)\n","Epoch 24 (fine-tuning)\n","Epoch 25 (fine-tuning)\n","Epoch 26 (fine-tuning)\n","Epoch 27 (fine-tuning)\n","Epoch 28 (fine-tuning)\n","Epoch 29 (fine-tuning)\n","Epoch 30 (fine-tuning)\n"]}],"source":["# Training setup\n","num_classes = 60\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = get_model_instance_segmentation(num_classes).to(device)\n","\n","# Phase 1: Freeze backbone\n","for name, param in model.backbone.named_parameters():\n","    param.requires_grad = False\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.AdamW(params, lr=1e-3, weight_decay=1e-4)\n","scaler = GradScaler()\n","\n","for epoch in range(1, 11):\n","    print(f\"Epoch {epoch} (frozen backbone)\")\n","    train(model, optimizer, scaler, data_loader, device)\n","    if epoch % 5 == 0:\n","        torch.save(model.state_dict(), f\"model_epoch_{epoch}_frozen.pth\")\n","\n","# Phase 2: Fine-tune full model\n","for param in model.backbone.parameters():\n","    param.requires_grad = True\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","\n","for epoch in range(11, 31):\n","    print(f\"Epoch {epoch} (fine-tuning)\")\n","    train(model, optimizer, scaler, data_loader, device)\n","    if epoch % 5 == 0:\n","        torch.save(model.state_dict(), f\"model_epoch_{epoch}_finetuned.pth\")\n","\n"]},{"cell_type":"code","source":["torch.save(model.state_dict(), f\"model_epoch_{epoch}_finetuned.pth\")"],"metadata":{"id":"NRjwkO_bGT_n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"jfjeAMsadxpF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_classes = 60\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = get_model_instance_segmentation(num_classes)\n","checkpoint_path = \"/content/drive/MyDrive/taco_models/30 epoch/model_epoch_30_finetuned.pth\"\n","model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n","model.to(device)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqKmg0Brfos6","outputId":"83f37260-209a-4dac-80b1-8abe7f35306d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_v2_coco-73cbd019.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_v2_coco-73cbd019.pth\n","100%|██████████| 177M/177M [00:00<00:00, 204MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["MaskRCNN(\n","  (transform): GeneralizedRCNNTransform(\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","  )\n","  (backbone): BackboneWithFPN(\n","    (body): IntermediateLayerGetter(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (fpn): FeaturePyramidNetwork(\n","      (inner_blocks): ModuleList(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (layer_blocks): ModuleList(\n","        (0-3): 4 x Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (extra_blocks): LastLevelMaxPool()\n","    )\n","  )\n","  (rpn): RegionProposalNetwork(\n","    (anchor_generator): AnchorGenerator()\n","    (head): RPNHead(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","      )\n","      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): RoIHeads(\n","    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n","    (box_head): FastRCNNConvFCHead(\n","      (0): Conv2dNormActivation(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (1): Conv2dNormActivation(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (2): Conv2dNormActivation(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (3): Conv2dNormActivation(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (4): Flatten(start_dim=1, end_dim=-1)\n","      (5): Linear(in_features=12544, out_features=1024, bias=True)\n","      (6): ReLU(inplace=True)\n","    )\n","    (box_predictor): FastRCNNPredictor(\n","      (cls_score): Linear(in_features=1024, out_features=60, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=240, bias=True)\n","    )\n","    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n","    (mask_head): MaskRCNNHeads(\n","      (0): Conv2dNormActivation(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (1): Conv2dNormActivation(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (2): Conv2dNormActivation(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (3): Conv2dNormActivation(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","    )\n","    (mask_predictor): MaskRCNNPredictor(\n","      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (relu): ReLU(inplace=True)\n","      (mask_fcn_logits): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from pycocotools.coco import COCO\n","\n","val_ann_file = os.path.join(data_dir, 'annotations_0_val.json')\n","coco_val = COCO(val_ann_file)\n","\n","val_annotations_list = []\n","for img_id in coco_val.getImgIds():\n","    img_info = coco_val.loadImgs(img_id)[0]\n","    ann_ids = coco_val.getAnnIds(imgIds=img_id)\n","    val_annotations_list.append({\n","        'image_id': img_id,\n","        'file_name': img_info['file_name'],\n","        'ann_ids': ann_ids,\n","        'height': img_info['height'],\n","        'width': img_info['width']\n","    })\n","\n","val_dataset = TACOInstanceSegmentationDataset(\n","    image_dir=data_dir,\n","    annotation_list=val_annotations_list,\n","    coco=coco_val,\n","    transforms=transform\n",")\n","category_id_to_name = {cat['id']: cat['name'] for cat in coco_val.loadCats(coco_val.getCatIds())}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DxedGE2bhcMW","outputId":"80273d30-b11c-4e0d-9ea9-7b72d63a71c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n"]}]},{"cell_type":"code","source":["import random\n","model.to('cpu')\n","\n","for i in random.sample(range(len(val_dataset)), 20):\n","    img, _ = val_dataset[i]\n","    with torch.no_grad():\n","        pred = model([img])[0]\n","    show_prediction(img, pred, category_id_to_name)\n"],"metadata":{"id":"YJRDePknhgJL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import numpy as np\n","import cv2\n","from PIL import Image\n","import torchvision.transforms.functional as F\n","import matplotlib.pyplot as plt\n","\n","def save_image_and_masks_with_overlay(model, image_path, output_dir, name, device='cuda', score_threshold=0.5):\n","    image_name = os.path.splitext(os.path.basename(image_path))[0]\n","    image_output_dir = os.path.join(output_dir, name)\n","    os.makedirs(image_output_dir, exist_ok=True)\n","\n","    img = Image.open(image_path).convert(\"RGB\")\n","    img_tensor = F.to_tensor(img).to(device)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        pred = model([img_tensor])[0]\n","\n","    image_png_path = os.path.join(image_output_dir, f\"{name}.png\")\n","    img.save(image_png_path)\n","\n","    image_np = np.array(img)\n","    overlay = image_np.copy()\n","\n","    masks = pred['masks'].cpu().numpy()\n","    scores = pred['scores'].cpu().numpy()\n","    labels = pred['labels'].cpu().numpy()\n","\n","    mask_count = 0\n","    for i, score in enumerate(scores):\n","        if score < score_threshold:\n","            continue\n","\n","        mask = (masks[i, 0] > 0.5).astype(np.uint8)\n","        mask_filename = os.path.join(image_output_dir, f\"{name}_mask_{mask_count}.png\")\n","        cv2.imwrite(mask_filename, mask * 255)\n","\n","        color = np.random.randint(0, 255, size=3, dtype=np.uint8)\n","        colored_mask = np.stack([mask * c for c in color], axis=-1)\n","\n","        overlay = np.where(mask[:, :, None], 0.5 * overlay + 0.5 * colored_mask, overlay)\n","\n","        mask_count += 1\n","\n","    overlay = overlay.astype(np.uint8)\n","    overlay_path = os.path.join(image_output_dir, f\"{name}_overlay.png\")\n","    Image.fromarray(overlay).save(overlay_path)\n","\n","    print(f\"Saved {mask_count} masks, original image, and overlay to: {image_output_dir}\")\n"],"metadata":{"id":"nURf8sonNWkv"},"execution_count":null,"outputs":[]}]}